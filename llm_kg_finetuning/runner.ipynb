{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a36b93b2-0800-4d2e-9f8f-1efbf569ab86",
   "metadata": {},
   "source": [
    "训练、测试、开发数据集分别是：\n",
    "\"train_file\": \"/mnt/d/forCoding_data/Tianchi_EcommerceKG/originalData/OpenBG500/OpenBG500_train.tsv\",\n",
    "\"test_file\": \"/mnt/d/forCoding_data/Tianchi_EcommerceKG/originalData/OpenBG500/OpenBG500_test.tsv\",\n",
    "\"dev_file\": \"/mnt/d/forCoding_data/Tianchi_EcommerceKG/originalData/OpenBG500/OpenBG500_dev.tsv\",\n",
    "你要拿训练数据去训练，然后在开发数据上看效果，最后在测试数据上做预测。\n",
    "\n",
    "这个任务是，给你头实体、关系，让你预测尾实体。实体和关系的中文文本映射文件路径\n",
    "\"entity_text_file\": \"/mnt/d/forCoding_data/Tianchi_EcommerceKG/originalData/OpenBG500/OpenBG500_entity2text.tsv\",\n",
    "\"relation_text_file\": \"/mnt/d/forCoding_data/Tianchi_EcommerceKG/originalData/OpenBG500/OpenBG500_relation2text.tsv\",\n",
    "\n",
    "你可以将实体和关系映射成中文之后，把映射关系做成prompt，比如说“input是`头实体是实体xxx，关系是关系yyy`，output是`正确的尾实体是zzz，错误的尾实体是aaa`”，其中错误的尾实体是负采样的。然后做一个lora微调或者其他形式的微调。\n",
    "\n",
    "我的显卡是4070TiS，显存16G，我的内存又32G，不要超过这个限度。预训练模型设置为Qwen/Qwen-1_8B-Chat，下载与训练模型的时候设置中国大陆的源以提升速度，权重文件存放地址设为/mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models，如果文件夹不存在就创建。可以使用cuDNN和deepspeed加速。做微调和推理的时候，请提高GPU使用率到百分之八九十。\n",
    "\n",
    "不要参考llm_kg_finetuning文件夹下的代码，请另起炉灶写一套代码，放在Tianchi_EcommerceKG文件夹下。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52f34666-0d1e-492d-bf44-5bf711317fbb",
   "metadata": {},
   "source": [
    "我有一个想法，请你帮我实现一下。训练数据里面有“实体1，关系，实体2”这样。我有一个方案，你看看合不合理，如果有不合理的地方请加以改进。然后再帮我设计一套实现方案：\n",
    "\n",
    "1. 数据里面的头实体尾实体和关系的代码，都用映射文件映射为其自然语言含义。\n",
    "\n",
    "2. 然后把映射\n",
    "\n",
    "3. 尽量使用一些deepspeed这种主流的库或者工具来做，还可以加入一些量化的小技巧，试图提高微调和推理的速度。\n",
    "\n",
    "4. 最后的模型，能够根据测试样本给出预测的尾实体，并且保证不会生成训练、开发、测试数据里面没见过的实体。\n",
    "\n",
    "5. 所有的代码都放到一个文件夹下，不要直接生成到根目录下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0a37b-523e-4a1a-a26c-8f242d8844ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2518c-a0c7-436b-a6c9-9a76c01028ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549e869-a960-480f-a5d6-d47fc8f09649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77569d0-8a51-4e22-8516-15a8f5af738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 安装deepspeed：\n",
    "### 先要给wsl再装一个cuda。然后再pip装deepspeed。\n",
    "### 参考资料：https://blog.csdn.net/FT2TC/article/details/149645598 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad6aca3-c473-41a4-91e5-bcd242982a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64546585-571e-40fe-a7a3-dd8889a5dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置文件不存在: ./config.json，使用默认配置\n",
      "===== 配置摘要 =====\n",
      "模型: THUDM/chatglm3-6b-base\n",
      "量化: 启用 (4位)\n",
      "LoRA: 启用 (rank=8)\n",
      "DeepSpee/mnt/d 禁用\n",
      "训练批次: 4 (累积8步)\n",
      "学习率: 2e-05\n",
      "训练轮数: 3\n",
      "负样本比例: 1\n",
      "输出目录: /mnt/d/forCoding_data/Tianchi_EcommerceKG/processedData/results\n",
      "模型保存目录: /mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models/models--THUDM--chatglm3-6b-base\n",
      "===================\n",
      "\n",
      "===== 开始训练流程 ====\n",
      "\n",
      "1. 加载数据...\n",
      "已加载训练集三元组: 1242550\n",
      "已加载测试集三元组: 5000\n",
      "已加载开发集三元组: 5000\n",
      "\n",
      "2. 加载实体和关系映射...\n",
      "已加载 249746 个实体文本映射\n",
      "已加载 500 个关系文本映射\n",
      "\n",
      "3. 准备训练数据...\n",
      "\n",
      "准备训练数据...\n",
      "总共收集到 249746 个唯一实体\n",
      "处理训练数据: 100%|███████████████| 1242550/1242550 [00:04<00:00, 293734.83it/s]\n",
      "处理开发数据: 100%|█████████████████████| 1000/1000 [00:00<00:00, 571664.71it/s]\n",
      "训练数据大小: 2485100\n",
      "开发数据大小: 1000\n",
      "\n",
      "4. 加载模型和分词器...\n",
      "\n",
      "加载模型: THUDM/chatglm3-6b-base...\n",
      "启用量化: 4位\n",
      "loading file tokenizer.model from cache at /mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models/models--THUDM--chatglm3-6b-base/models--THUDM--chatglm3-6b-base/snapshots/9680e216e62c3a69bc9eec480c35d59c325079bf/tokenizer.model\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models/models--THUDM--chatglm3-6b-base/models--THUDM--chatglm3-6b-base/snapshots/9680e216e62c3a69bc9eec480c35d59c325079bf/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models/models--THUDM--chatglm3-6b-base/models--THUDM--chatglm3-6b-base/snapshots/9680e216e62c3a69bc9eec480c35d59c325079bf/config.json\n",
      "loading configuration file config.json from cache at /mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models/models--THUDM--chatglm3-6b-base/models--THUDM--chatglm3-6b-base/snapshots/9680e216e62c3a69bc9eec480c35d59c325079bf/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 32768,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.55.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models/models--THUDM--chatglm3-6b-base/models--THUDM--chatglm3-6b-base/snapshots/9680e216e62c3a69bc9eec480c35d59c325079bf/pytorch_model.bin.index.json\n",
      "Fetching 7 files:   0%|                                   | 0/7 [00:00<?, ?it/s]\n",
      "pytorch_model-00003-of-00007.bin:   0%|             | 0.00/1.93G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00007.bin:   0%|             | 0.00/1.83G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00007.bin:   0%|             | 0.00/1.97G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00007-of-00007.bin:   0%|             | 0.00/1.05G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00004-of-00007.bin:   0%|             | 0.00/1.82G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00005-of-00007.bin:   0%|             | 0.00/1.97G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00006-of-00007.bin:   0%|             | 0.00/1.93G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00003-of-00007.bin:   3%|▏   | 67.0M/1.93G [00:02<01:15, 24.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00007.bin:   0%|    | 748k/1.97G [00:03<2:22:00, 231kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00004-of-00007.bin:   0%|    | 894k/1.82G [00:03<1:57:27, 257kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00007.bin:   0%|    | 748k/1.97G [00:14<2:22:00, 231kB/s]\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00003-of-00007.bin:   3%|▏   | 67.0M/1.93G [00:14<01:15, 24.8MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00004-of-00007.bin:   7%|▎   | 135M/1.82G [00:14<1:48:46, 257kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00007.bin:   0%| | 980k/1.83G [08:59<279:35:01, 1.82kB/s]\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00007.bin:   4%| | 68.1M/1.83G [09:15<269:18:52, 1.82kB/s\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00004-of-00007.bin:  11%|▍   | 202M/1.82G [09:27<1:15:26, 356kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00004-of-00007.bin:  15%|▌   | 269M/1.82G [09:44<1:12:18, 356kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00007.bin:   3%|   | 67.9M/1.97G [10:04<4:42:39, 112kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00007.bin:   7%|▎   | 135M/1.83G [10:06<1:33:03, 303kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00004-of-00007.bin:  19%|█     | 336M/1.82G [10:08<39:10, 629kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00006-of-00007.bin:   0%| | 1.86M/1.93G [10:11<175:43:06, 3.04kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00007.bin:   3%|   | 67.9M/1.97G [10:15<4:42:39, 112kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00007-of-00007.bin:   0%| | 1.92M/1.05G [10:20<94:09:52, 3.10kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00005-of-00007.bin:   0%|  | 310k/1.97G [10:22<1097:20:01, 498B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00007.bin:   7%|▎   | 135M/1.97G [10:22<1:57:40, 260kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00007.bin:  11%|▍   | 202M/1.83G [10:25<1:29:22, 303kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00004-of-00007.bin:  19%|█     | 336M/1.82G [10:24<39:10, 629kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00006-of-00007.bin:   0%| | 1.86M/1.93G [10:24<175:43:06, 3.04kB/s\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00004-of-00007.bin:  22%|█▎    | 403M/1.82G [10:26<29:25, 800kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "pytorch_model-00003-of-00007.bin:   4%|  | 68.0M/1.93G [10:27<6:45:28, 76.4kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00006-of-00007.bin:   0%| | 4.85M/1.93G [10:32<55:53:51, 9.55kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00005-of-00007.bin:   0%|  | 310k/1.97G [10:34<1097:20:01, 498B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "pytorch_model-00002-of-00007.bin:  10%|▍   | 202M/1.97G [10:35<1:53:21, 260kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00007-of-00007.bin:   0%| | 1.92M/1.05G [10:34<94:09:52, 3.10kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00007-of-00007.bin:   0%| | 2.12M/1.05G [10:35<85:10:23, 3.43kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00005-of-00007.bin:   0%| | 931k/1.97G [10:36<293:30:03, 1.86kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00007.bin:  15%|▉     | 269M/1.83G [10:42<39:24, 659kB/s]\u001b[A\u001b[A\n",
      "pytorch_model-00003-of-00007.bin:   4%|  | 68.0M/1.93G [10:45<6:45:28, 76.4kB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00004-of-00007.bin:  22%|█▎    | 403M/1.82G [10:44<29:25, 800kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00006-of-00007.bin:   0%| | 4.85M/1.93G [10:44<55:53:51, 9.55kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00005-of-00007.bin:   0%| | 931k/1.97G [10:54<293:30:03, 1.86kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "pytorch_model-00001-of-00007.bin:  15%|▉     | 269M/1.83G [10:55<39:24, 659kB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00007-of-00007.bin:   0%| | 2.12M/1.05G [10:54<85:10:23, 3.43kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00004-of-00007.bin:  26%|█▌    | 470M/1.82G [11:09<24:20, 921kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00006-of-00007.bin:   0%| | 4.94M/1.93G [11:21<62:38:04, 8.53kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00004-of-00007.bin:  33%|█▉    | 604M/1.82G [11:24<21:55, 921kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "pytorch_model-00007-of-00007.bin:   0%| | 4.45M/1.05G [11:27<31:21:03, 9.29kB/s]\u001b[A\u001b[A\u001b[A\u001b[A^C\n",
      "Cancellation requested; stopping current tasks.\n",
      "pytorch_model-00007-of-00007.bin:   0%| | 4.45M/1.05G [11:30<45:12:49, 6.44kB/s]\n",
      "pytorch_model-00006-of-00007.bin:   0%| | 4.94M/1.93G [11:30<74:36:15, 7.16kB/s]\n",
      "pytorch_model-00004-of-00007.bin:  33%|█▉    | 604M/1.82G [11:30<23:03, 875kB/s]\n",
      "pytorch_model-00005-of-00007.bin:   0%| | 931k/1.97G [11:30<405:23:13, 1.35kB/s]\n",
      "pytorch_model-00003-of-00007.bin:   4%|  | 68.0M/1.93G [11:30<5:14:41, 98.5kB/s]\n",
      "pytorch_model-00001-of-00007.bin:  15%|▌   | 269M/1.83G [11:30<1:06:38, 390kB/s]\n",
      "pytorch_model-00002-of-00007.bin:  10%|▍   | 202M/1.97G [11:30<1:40:37, 293kB/s]\n",
      "Fetching 7 files:   0%|                                   | 0/7 [11:31<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --mode train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc841b5a-3760-4363-a060-d27326467be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac183e-4a6d-4246-9140-8d1aad909d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8377b85-2a86-4c60-a39b-4d4e88488e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad30b3e-24d0-4a88-a304-f145ed00443f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d2f94-2f03-4256-8a54-95cf834e561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/mnt/d/forCoding_data/Tianchi_EcommerceKG/trained_models/models--THUDM--chatglm3-6b-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447f59cd-c02b-4c10-bc98-f57d7d9467bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f10483-7156-43fc-b35c-d063a96ffa5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de48f80-80e5-4946-8eb9-2b50410c44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/mnt/d/forCoding_data/\"\n",
    "\n",
    "\n",
    "/home/xiuminke/.cache/huggingface/hub/models--THUDM--chatglm3-6b-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf42e50-97ac-4992-a54b-c6c1d7d3b019",
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py --mode predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a63ef-b72e-44a2-9dc5-7c1ce0bd28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "python train.py --mode eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7032fb6-ffd8-4edf-8585-bce9429c45fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf529b-08eb-4db4-844d-5a7fa0cebe47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
