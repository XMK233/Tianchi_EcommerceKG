2025-09-28 11:36:35,663 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 11:41:19,860 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 11:41:37,433 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/9d5126a57f942e4542692700384a9d2b61f1e7fb7c3a91db0280a8c54c338c49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034126Z&X-Amz-Expires=3600&X-Amz-Signature=d88758577db3393d2eee838b76e2e13abd0368b76991ab92d574f7502b970112&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034486&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDQ4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvOWQ1MTI2YTU3Zjk0MmU0NTQyNjkyNzAwMzg0YTlkMmI2MWYxZTdmYjdjM2E5MWRiMDI4MGE4YzU0YzMzOGM0OSoifV19&Signature=ptltW5et9i8-wjsZbbIyWLlx-sh0k1nADyKxIOow76OuiQI5OxdEzOt0qAMY1J277GX-uHSi-N-GVlIwo1Z8c66y7EMC9m-aZlrgp-tIWi41LIq05XaKhARL-9Qe5oFmTwsiJyz%7EyhA1Yi6UuuTNNiJSXEdpjMcPxaQLTH1iR8JlMSScH1RolyLmNvqqGgmZwwhppKWnG72yB9TJn-w5H99F25bdoiSRJkLZMmLUclVY0d2Tn6qlVqwqSCYdIFw96yexcr1HL9WvonqG2yyA9UVDZlEUSWXy2s8yapbJFotWWB7-V8vSUqb2yhsNseC9URRRZUaRGBbvHs-sRnW5Hg__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:41:49,071 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/9d5126a57f942e4542692700384a9d2b61f1e7fb7c3a91db0280a8c54c338c49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034126Z&X-Amz-Expires=3600&X-Amz-Signature=d88758577db3393d2eee838b76e2e13abd0368b76991ab92d574f7502b970112&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034486&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDQ4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvOWQ1MTI2YTU3Zjk0MmU0NTQyNjkyNzAwMzg0YTlkMmI2MWYxZTdmYjdjM2E5MWRiMDI4MGE4YzU0YzMzOGM0OSoifV19&Signature=ptltW5et9i8-wjsZbbIyWLlx-sh0k1nADyKxIOow76OuiQI5OxdEzOt0qAMY1J277GX-uHSi-N-GVlIwo1Z8c66y7EMC9m-aZlrgp-tIWi41LIq05XaKhARL-9Qe5oFmTwsiJyz%7EyhA1Yi6UuuTNNiJSXEdpjMcPxaQLTH1iR8JlMSScH1RolyLmNvqqGgmZwwhppKWnG72yB9TJn-w5H99F25bdoiSRJkLZMmLUclVY0d2Tn6qlVqwqSCYdIFw96yexcr1HL9WvonqG2yyA9UVDZlEUSWXy2s8yapbJFotWWB7-V8vSUqb2yhsNseC9URRRZUaRGBbvHs-sRnW5Hg__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:42:00,919 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/9d5126a57f942e4542692700384a9d2b61f1e7fb7c3a91db0280a8c54c338c49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034126Z&X-Amz-Expires=3600&X-Amz-Signature=d88758577db3393d2eee838b76e2e13abd0368b76991ab92d574f7502b970112&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034486&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDQ4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvOWQ1MTI2YTU3Zjk0MmU0NTQyNjkyNzAwMzg0YTlkMmI2MWYxZTdmYjdjM2E5MWRiMDI4MGE4YzU0YzMzOGM0OSoifV19&Signature=ptltW5et9i8-wjsZbbIyWLlx-sh0k1nADyKxIOow76OuiQI5OxdEzOt0qAMY1J277GX-uHSi-N-GVlIwo1Z8c66y7EMC9m-aZlrgp-tIWi41LIq05XaKhARL-9Qe5oFmTwsiJyz%7EyhA1Yi6UuuTNNiJSXEdpjMcPxaQLTH1iR8JlMSScH1RolyLmNvqqGgmZwwhppKWnG72yB9TJn-w5H99F25bdoiSRJkLZMmLUclVY0d2Tn6qlVqwqSCYdIFw96yexcr1HL9WvonqG2yyA9UVDZlEUSWXy2s8yapbJFotWWB7-V8vSUqb2yhsNseC9URRRZUaRGBbvHs-sRnW5Hg__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:42:27,869 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/c4fed2e4683886fcf7ce468760b5a63415438ad67d3b57fa39edca3f161a7aec?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034126Z&X-Amz-Expires=3600&X-Amz-Signature=708f3f35b6b46d9708c1461742b00adb512e267314bf0cda151e66f18c000138&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034486&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDQ4Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvYzRmZWQyZTQ2ODM4ODZmY2Y3Y2U0Njg3NjBiNWE2MzQxNTQzOGFkNjdkM2I1N2ZhMzllZGNhM2YxNjFhN2FlYyoifV19&Signature=Tj3lGxFkiGgSLbK4DC%7E8qNMF7JGIhn5mE7QnBnAB%7EN-7mWPvMLlIYEz%7EbaoEswaelxwZAPSZTirbPS86xZmd5vXMXfU3xF3y342gz08tNs5HZwU6C4gDqdiQAVB1cpRFlQqJD-M4LZyC-H6r9F7WGMkL6e3Grb0XWyqnoWDxIhv3gRQ%7EK7ze1tJT%7ELSWju6a-RgG2s%7ExBjM8Gf6y9CEfWQesgmnwBpNdtim%7EV83HIMNez59Snz5a8KlL1sgZMrrM-BkiFD9zAToWyyeoqAd-DeT05Ox01uHv8dfu--RWEbojlRocy9lvTaRvGC2h3DqpS9wjhDfArkvw2iH5rfzjBQ__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:45:52,841 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 11:46:06,768 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/c4fed2e4683886fcf7ce468760b5a63415438ad67d3b57fa39edca3f161a7aec?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034555Z&X-Amz-Expires=3600&X-Amz-Signature=993b73b927774fb1afe61d9cec929b33f4122b38ca0ca692194a646fc5f4d968&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvYzRmZWQyZTQ2ODM4ODZmY2Y3Y2U0Njg3NjBiNWE2MzQxNTQzOGFkNjdkM2I1N2ZhMzllZGNhM2YxNjFhN2FlYyoifV19&Signature=uEzea7iZ-ko36LQWWUk93ntvD7SIM%7EMEnd786FBMllgk0sSrha7-SlHzNWPZOwY7w8Uj9eBrSqKN6TAn-FBI6CulGl6B4IuXCi3xMyGG9Y-vPEVGz9-6uUSaucBIwj8tLxcq94yh7TfMTBfJf-n27q582WZT8z-aSAvzj8Mci1lBZbV-6GpNGeg5tKGymOf8LJF8-f24E123DnZ2HUkVQJqT1EK0u8-oX0SK1Z2y39tyiqWsg7vl6Vdh688fi2o1BmYh-b-DClh25A%7EjpKFzIWisJzuC78fCRMnuCRxtyvKjuykQoOgAAPe25DRAjqAZcnKBzJ229tBTGj1Ux5QmXw__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:46:18,633 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/c4fed2e4683886fcf7ce468760b5a63415438ad67d3b57fa39edca3f161a7aec?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034555Z&X-Amz-Expires=3600&X-Amz-Signature=993b73b927774fb1afe61d9cec929b33f4122b38ca0ca692194a646fc5f4d968&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvYzRmZWQyZTQ2ODM4ODZmY2Y3Y2U0Njg3NjBiNWE2MzQxNTQzOGFkNjdkM2I1N2ZhMzllZGNhM2YxNjFhN2FlYyoifV19&Signature=uEzea7iZ-ko36LQWWUk93ntvD7SIM%7EMEnd786FBMllgk0sSrha7-SlHzNWPZOwY7w8Uj9eBrSqKN6TAn-FBI6CulGl6B4IuXCi3xMyGG9Y-vPEVGz9-6uUSaucBIwj8tLxcq94yh7TfMTBfJf-n27q582WZT8z-aSAvzj8Mci1lBZbV-6GpNGeg5tKGymOf8LJF8-f24E123DnZ2HUkVQJqT1EK0u8-oX0SK1Z2y39tyiqWsg7vl6Vdh688fi2o1BmYh-b-DClh25A%7EjpKFzIWisJzuC78fCRMnuCRxtyvKjuykQoOgAAPe25DRAjqAZcnKBzJ229tBTGj1Ux5QmXw__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:46:30,235 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/c4fed2e4683886fcf7ce468760b5a63415438ad67d3b57fa39edca3f161a7aec?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034555Z&X-Amz-Expires=3600&X-Amz-Signature=993b73b927774fb1afe61d9cec929b33f4122b38ca0ca692194a646fc5f4d968&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvYzRmZWQyZTQ2ODM4ODZmY2Y3Y2U0Njg3NjBiNWE2MzQxNTQzOGFkNjdkM2I1N2ZhMzllZGNhM2YxNjFhN2FlYyoifV19&Signature=uEzea7iZ-ko36LQWWUk93ntvD7SIM%7EMEnd786FBMllgk0sSrha7-SlHzNWPZOwY7w8Uj9eBrSqKN6TAn-FBI6CulGl6B4IuXCi3xMyGG9Y-vPEVGz9-6uUSaucBIwj8tLxcq94yh7TfMTBfJf-n27q582WZT8z-aSAvzj8Mci1lBZbV-6GpNGeg5tKGymOf8LJF8-f24E123DnZ2HUkVQJqT1EK0u8-oX0SK1Z2y39tyiqWsg7vl6Vdh688fi2o1BmYh-b-DClh25A%7EjpKFzIWisJzuC78fCRMnuCRxtyvKjuykQoOgAAPe25DRAjqAZcnKBzJ229tBTGj1Ux5QmXw__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:46:48,443 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/c4fed2e4683886fcf7ce468760b5a63415438ad67d3b57fa39edca3f161a7aec?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034555Z&X-Amz-Expires=3600&X-Amz-Signature=993b73b927774fb1afe61d9cec929b33f4122b38ca0ca692194a646fc5f4d968&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvYzRmZWQyZTQ2ODM4ODZmY2Y3Y2U0Njg3NjBiNWE2MzQxNTQzOGFkNjdkM2I1N2ZhMzllZGNhM2YxNjFhN2FlYyoifV19&Signature=uEzea7iZ-ko36LQWWUk93ntvD7SIM%7EMEnd786FBMllgk0sSrha7-SlHzNWPZOwY7w8Uj9eBrSqKN6TAn-FBI6CulGl6B4IuXCi3xMyGG9Y-vPEVGz9-6uUSaucBIwj8tLxcq94yh7TfMTBfJf-n27q582WZT8z-aSAvzj8Mci1lBZbV-6GpNGeg5tKGymOf8LJF8-f24E123DnZ2HUkVQJqT1EK0u8-oX0SK1Z2y39tyiqWsg7vl6Vdh688fi2o1BmYh-b-DClh25A%7EjpKFzIWisJzuC78fCRMnuCRxtyvKjuykQoOgAAPe25DRAjqAZcnKBzJ229tBTGj1Ux5QmXw__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:47:34,602 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/c4fed2e4683886fcf7ce468760b5a63415438ad67d3b57fa39edca3f161a7aec?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034555Z&X-Amz-Expires=3600&X-Amz-Signature=993b73b927774fb1afe61d9cec929b33f4122b38ca0ca692194a646fc5f4d968&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvYzRmZWQyZTQ2ODM4ODZmY2Y3Y2U0Njg3NjBiNWE2MzQxNTQzOGFkNjdkM2I1N2ZhMzllZGNhM2YxNjFhN2FlYyoifV19&Signature=uEzea7iZ-ko36LQWWUk93ntvD7SIM%7EMEnd786FBMllgk0sSrha7-SlHzNWPZOwY7w8Uj9eBrSqKN6TAn-FBI6CulGl6B4IuXCi3xMyGG9Y-vPEVGz9-6uUSaucBIwj8tLxcq94yh7TfMTBfJf-n27q582WZT8z-aSAvzj8Mci1lBZbV-6GpNGeg5tKGymOf8LJF8-f24E123DnZ2HUkVQJqT1EK0u8-oX0SK1Z2y39tyiqWsg7vl6Vdh688fi2o1BmYh-b-DClh25A%7EjpKFzIWisJzuC78fCRMnuCRxtyvKjuykQoOgAAPe25DRAjqAZcnKBzJ229tBTGj1Ux5QmXw__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:47:46,249 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/c4fed2e4683886fcf7ce468760b5a63415438ad67d3b57fa39edca3f161a7aec?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034555Z&X-Amz-Expires=3600&X-Amz-Signature=993b73b927774fb1afe61d9cec929b33f4122b38ca0ca692194a646fc5f4d968&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvYzRmZWQyZTQ2ODM4ODZmY2Y3Y2U0Njg3NjBiNWE2MzQxNTQzOGFkNjdkM2I1N2ZhMzllZGNhM2YxNjFhN2FlYyoifV19&Signature=uEzea7iZ-ko36LQWWUk93ntvD7SIM%7EMEnd786FBMllgk0sSrha7-SlHzNWPZOwY7w8Uj9eBrSqKN6TAn-FBI6CulGl6B4IuXCi3xMyGG9Y-vPEVGz9-6uUSaucBIwj8tLxcq94yh7TfMTBfJf-n27q582WZT8z-aSAvzj8Mci1lBZbV-6GpNGeg5tKGymOf8LJF8-f24E123DnZ2HUkVQJqT1EK0u8-oX0SK1Z2y39tyiqWsg7vl6Vdh688fi2o1BmYh-b-DClh25A%7EjpKFzIWisJzuC78fCRMnuCRxtyvKjuykQoOgAAPe25DRAjqAZcnKBzJ229tBTGj1Ux5QmXw__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Max retries exceeded.
2025-09-28 11:49:33,100 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/9d5126a57f942e4542692700384a9d2b61f1e7fb7c3a91db0280a8c54c338c49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034555Z&X-Amz-Expires=3600&X-Amz-Signature=456919490c9aa6010d0665c9ed49330795d8a709d6954a8c55b9d2e03ff9eb1d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvOWQ1MTI2YTU3Zjk0MmU0NTQyNjkyNzAwMzg0YTlkMmI2MWYxZTdmYjdjM2E5MWRiMDI4MGE4YzU0YzMzOGM0OSoifV19&Signature=UkDbVGd0xWopCLiwZ2XgW-QdVRb-qWSn6SlrEATyEOQcIfChAmCT6wsCJBLc1Es9VkmgaIWRFbyNFyxNgCcIWp2%7EmE%7EfQdGjPw4oR10XtYvjirRcDrgc%7EaaZFHS%7E0-RcjTIUDXA0U85JZ4qvDrHiGPVcqB4NPyPJZU4q4dmIi2H420IValAn0QE8kLIWaIvqaTOwBgZkmTCpk0zKZSHTwJX8LyM3d%7Ev4KZc0owovnQvk1ehiV3a-32sfX%7EJ3esLbA9IYFHZBLxJEUWqBggqLMAFUkQEnDlO9maV-XHn07C8xytxyzKS4QLUTCChoW0bkN9v9oF7sWP538AKW7i6lKA__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:49:49,996 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/9d5126a57f942e4542692700384a9d2b61f1e7fb7c3a91db0280a8c54c338c49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034555Z&X-Amz-Expires=3600&X-Amz-Signature=456919490c9aa6010d0665c9ed49330795d8a709d6954a8c55b9d2e03ff9eb1d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvOWQ1MTI2YTU3Zjk0MmU0NTQyNjkyNzAwMzg0YTlkMmI2MWYxZTdmYjdjM2E5MWRiMDI4MGE4YzU0YzMzOGM0OSoifV19&Signature=UkDbVGd0xWopCLiwZ2XgW-QdVRb-qWSn6SlrEATyEOQcIfChAmCT6wsCJBLc1Es9VkmgaIWRFbyNFyxNgCcIWp2%7EmE%7EfQdGjPw4oR10XtYvjirRcDrgc%7EaaZFHS%7E0-RcjTIUDXA0U85JZ4qvDrHiGPVcqB4NPyPJZU4q4dmIi2H420IValAn0QE8kLIWaIvqaTOwBgZkmTCpk0zKZSHTwJX8LyM3d%7Ev4KZc0owovnQvk1ehiV3a-32sfX%7EJ3esLbA9IYFHZBLxJEUWqBggqLMAFUkQEnDlO9maV-XHn07C8xytxyzKS4QLUTCChoW0bkN9v9oF7sWP538AKW7i6lKA__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:50:01,602 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/9d5126a57f942e4542692700384a9d2b61f1e7fb7c3a91db0280a8c54c338c49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034555Z&X-Amz-Expires=3600&X-Amz-Signature=456919490c9aa6010d0665c9ed49330795d8a709d6954a8c55b9d2e03ff9eb1d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvOWQ1MTI2YTU3Zjk0MmU0NTQyNjkyNzAwMzg0YTlkMmI2MWYxZTdmYjdjM2E5MWRiMDI4MGE4YzU0YzMzOGM0OSoifV19&Signature=UkDbVGd0xWopCLiwZ2XgW-QdVRb-qWSn6SlrEATyEOQcIfChAmCT6wsCJBLc1Es9VkmgaIWRFbyNFyxNgCcIWp2%7EmE%7EfQdGjPw4oR10XtYvjirRcDrgc%7EaaZFHS%7E0-RcjTIUDXA0U85JZ4qvDrHiGPVcqB4NPyPJZU4q4dmIi2H420IValAn0QE8kLIWaIvqaTOwBgZkmTCpk0zKZSHTwJX8LyM3d%7Ev4KZc0owovnQvk1ehiV3a-32sfX%7EJ3esLbA9IYFHZBLxJEUWqBggqLMAFUkQEnDlO9maV-XHn07C8xytxyzKS4QLUTCChoW0bkN9v9oF7sWP538AKW7i6lKA__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:50:13,208 - WARNING - Error while downloading from https://cas-bridge.xethub.hf-mirror.com/xet-bridge-us/6567f9cbd0a121b8e8049cad/9d5126a57f942e4542692700384a9d2b61f1e7fb7c3a91db0280a8c54c338c49?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250928%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250928T034555Z&X-Amz-Expires=3600&X-Amz-Signature=456919490c9aa6010d0665c9ed49330795d8a709d6954a8c55b9d2e03ff9eb1d&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=62171e3b6a99db28e0b3159d&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1759034755&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1OTAzNDc1NX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTY3ZjljYmQwYTEyMWI4ZTgwNDljYWQvOWQ1MTI2YTU3Zjk0MmU0NTQyNjkyNzAwMzg0YTlkMmI2MWYxZTdmYjdjM2E5MWRiMDI4MGE4YzU0YzMzOGM0OSoifV19&Signature=UkDbVGd0xWopCLiwZ2XgW-QdVRb-qWSn6SlrEATyEOQcIfChAmCT6wsCJBLc1Es9VkmgaIWRFbyNFyxNgCcIWp2%7EmE%7EfQdGjPw4oR10XtYvjirRcDrgc%7EaaZFHS%7E0-RcjTIUDXA0U85JZ4qvDrHiGPVcqB4NPyPJZU4q4dmIi2H420IValAn0QE8kLIWaIvqaTOwBgZkmTCpk0zKZSHTwJX8LyM3d%7Ev4KZc0owovnQvk1ehiV3a-32sfX%7EJ3esLbA9IYFHZBLxJEUWqBggqLMAFUkQEnDlO9maV-XHn07C8xytxyzKS4QLUTCChoW0bkN9v9oF7sWP538AKW7i6lKA__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf-mirror.com', port=443): Read timed out.
Trying to resume download...
2025-09-28 11:51:14,418 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 11:51:17,522 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 11:51:17,522 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 11:51:17,523 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 11:51:17,523 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 11:51:17,524 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 11:51:17,854 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 11:51:35,487 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 11:51:35,487 - INFO - 模型加载完成，耗时: 21.07秒
2025-09-28 12:00:45,008 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:00:50,149 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 12:00:50,149 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 12:00:50,150 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 12:00:50,151 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 12:00:50,152 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 12:00:50,457 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 12:01:03,305 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 12:01:03,307 - INFO - 模型加载完成，耗时: 18.30秒
2025-09-28 12:04:39,627 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:04:42,862 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 12:04:42,862 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 12:04:42,863 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 12:04:42,863 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 12:04:42,864 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 12:04:43,171 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 12:04:55,454 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 12:04:55,455 - INFO - 模型加载完成，耗时: 15.83秒
2025-09-28 12:08:22,802 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:08:25,702 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 12:08:25,702 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 12:08:25,703 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 12:08:25,704 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 12:08:25,705 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 12:08:26,007 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 12:08:38,358 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 12:08:38,359 - INFO - 模型加载完成，耗时: 15.56秒
2025-09-28 12:13:57,955 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:14:01,397 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 12:14:01,397 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 12:14:01,398 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 12:14:01,399 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 12:14:01,399 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 12:14:01,676 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 12:14:14,451 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 12:14:14,451 - INFO - 模型加载完成，耗时: 16.50秒
2025-09-28 12:16:11,031 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:16:14,239 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 12:16:14,239 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 12:16:14,239 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 12:16:14,240 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 12:16:14,240 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 12:16:14,496 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 12:16:26,825 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 12:16:26,826 - INFO - 模型加载完成，耗时: 15.79秒
2025-09-28 12:18:47,760 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:18:50,776 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 12:18:50,776 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 12:18:50,777 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 12:18:50,777 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 12:18:50,778 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 12:18:51,026 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 12:19:03,981 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 12:19:03,982 - INFO - 模型加载完成，耗时: 16.22秒
2025-09-28 12:23:19,566 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:23:22,573 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 12:23:22,573 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 12:23:22,574 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 12:23:22,575 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 12:23:22,575 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 12:23:22,821 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 12:23:34,907 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 12:23:34,907 - INFO - 模型加载完成，耗时: 15.34秒
2025-09-28 12:27:56,424 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:30:49,970 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:30:53,169 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 12:30:53,170 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 12:30:53,170 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 12:30:53,171 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 12:30:53,171 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 12:30:53,467 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 12:31:06,594 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 12:31:06,596 - INFO - 模型加载完成，耗时: 16.63秒
2025-09-28 12:34:11,462 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:34:14,641 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 12:34:14,641 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 12:34:14,642 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 12:34:14,643 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 12:34:14,643 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 12:34:14,896 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 12:34:27,088 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 12:34:27,090 - INFO - 模型加载完成，耗时: 15.63秒
2025-09-28 12:38:08,909 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:47:38,688 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 12:58:45,941 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 13:03:07,745 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 13:03:08,993 - INFO - 无法设置具体的pad_token，使用默认值: <|padding|>
2025-09-28 13:03:08,993 - WARNING - 设置pad_token时出错: Cannot set a non-string value as the pad_token
2025-09-28 13:03:10,694 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 13:03:10,694 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 13:03:10,695 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 13:03:10,696 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 13:03:10,696 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 13:03:10,999 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 13:03:23,988 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 13:03:23,989 - INFO - 模型加载完成，耗时: 16.24秒
2025-09-28 13:08:16,451 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 13:12:20,493 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 13:12:21,685 - INFO - eos_token和unk_token都不存在，尝试使用安全的方式设置pad_token
2025-09-28 13:12:21,686 - INFO - 已设置pad_token为默认安全值: <|padding|>
2025-09-28 13:12:23,385 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 13:12:23,385 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 13:12:23,386 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 13:12:23,387 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 13:12:23,387 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 13:12:23,686 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 13:12:36,402 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 13:12:36,407 - INFO - 模型加载完成，耗时: 15.91秒
2025-09-28 13:17:05,891 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 13:17:07,348 - INFO - eos_token和unk_token都不存在，尝试使用安全的方式设置pad_token
2025-09-28 13:17:07,349 - INFO - 已设置pad_token为默认安全值: <|padding|>
2025-09-28 13:17:07,349 - WARNING - pad_token_id仍然为None，尝试使用最安全的方式解决...
2025-09-28 13:17:07,350 - INFO - 已成功应用tokenizer包装，避免对pad_token_id的检查
2025-09-28 13:17:09,601 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 13:17:09,601 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 13:17:09,601 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 13:17:09,602 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 13:17:09,603 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 13:17:09,875 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 13:17:21,710 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 13:17:21,711 - INFO - 模型加载完成，耗时: 15.82秒
2025-09-28 13:20:30,209 - INFO - 开始加载模型: Qwen/Qwen-1_8B-Chat
2025-09-28 13:20:31,541 - INFO - eos_token和unk_token都不存在，尝试使用安全的方式设置pad_token
2025-09-28 13:20:31,542 - INFO - 已设置pad_token为默认安全值: <|padding|>
2025-09-28 13:20:31,542 - WARNING - pad_token_id仍然为None，尝试使用最安全的方式解决...
2025-09-28 13:20:31,542 - INFO - 已设置假的pad_token_id: 151643
2025-09-28 13:20:33,249 - WARNING - The model is automatically converting to bf16 for faster inference. If you want to disable the automatic precision, please manually add bf16/fp16/fp32=True to "AutoModelForCausalLM.from_pretrained".
2025-09-28 13:20:33,249 - WARNING - Try importing flash-attention for faster inference...
2025-09-28 13:20:33,249 - WARNING - Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
2025-09-28 13:20:33,250 - WARNING - Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
2025-09-28 13:20:33,251 - WARNING - Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
2025-09-28 13:20:33,515 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-09-28 13:20:46,641 - INFO - 可训练参数: 1.57M (0.13%)
2025-09-28 13:20:46,643 - INFO - 模型加载完成，耗时: 16.43秒
